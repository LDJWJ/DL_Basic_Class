{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "2.4.3\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array(12)\n",
    "print(x.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([10,20,30,40,50])\n",
    "print(x.ndim)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 행렬 (2D 텐서)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 벡터의 배열을 행렬(matrix) 또는 2D텐서라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array( [ [11,21,31],\n",
    "                [12,22,32],\n",
    "                [13,23,33]\n",
    "              ])\n",
    "print(x.ndim)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[11, 21, 31],\n",
       "        [12, 22, 32],\n",
       "        [13, 23, 33]],\n",
       "\n",
       "       [[11, 21, 31],\n",
       "        [12, 22, 32],\n",
       "        [13, 23, 33]],\n",
       "\n",
       "       [[11, 21, 31],\n",
       "        [12, 22, 32],\n",
       "        [13, 23, 33]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([\n",
    "              [ [11,21,31],\n",
    "               [12,22,32],\n",
    "               [13,23,33] ],\n",
    "              [ [11,21,31],\n",
    "               [12,22,32],\n",
    "               [13,23,33] ],\n",
    "              [ [11,21,31],\n",
    "               [12,22,32],\n",
    "               [13,23,33] ]\n",
    "             ])\n",
    "print(x.ndim)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.ndim)\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 출력해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = train_images[5]\n",
    "plt.imshow(image, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 넘파이를 활용한 텐서 조작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "my_slice = train_images[10:50]\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "my_slice = train_images[10:50, :, :]\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 14, 14)\n"
     ]
    }
   ],
   "source": [
    "my_slice = train_images[: , 14:, 14:]\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = my_slice[5]\n",
    "plt.imshow(image, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 21)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_slice = train_images[5, 4:24, 4:25]\n",
    "print(my_slice.shape)\n",
    "\n",
    "plt.imshow(my_slice, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 06 배치 데이터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 딥러닝 모델에서는 한번 전체 데이타를 처리하지 않고, \n",
    "### 그대신 데이터를 작은 배치(batch)로 나눈다.\n",
    "batch = train_images[ : 128]\n",
    "next_batch = train_images[128:256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (60000, 28, 28)  색이 없었던 것.\n",
    "# (60000, 28, 28, 3)  RGB 색이 있어요.\n",
    "# 2D : 행렬(타이타닉, 바이크)..\n",
    "# 3D : 시계열 데이터 \n",
    "# 4D : (샘플개수, 높이, 너비, 채널) 채널1:흑백, 채널3(RGB):3\n",
    "# 5D : 동영상 (샘플개수, 프레임, 높이, 너비, 채널)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서의 크기 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "train_images = train_images.reshape((60000, 28*28))  # 3D -> 2D\n",
    "print( train_images.ndim)\n",
    "print( train_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## parse_dates : datetime 컬럼을 시간형으로 불러올 수 있음\n",
    "train = pd.read_csv(\"bike_mod_tr.csv\", parse_dates=['datetime'])\n",
    "test = pd.read_csv(\"bike_mod_test.csv\", parse_dates=['datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'season', 'holiday', 'workingday', 'weather', 'temp',\n",
       "       'atemp', 'humidity', 'windspeed', 'casual', 'registered', 'count',\n",
       "       'year', 'month', 'day', 'hour', 'minute', 'second', 'dayofweek'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_col = ['hour', 'temp']\n",
    "input_col = ['hour', 'temp', 'dayofweek', 'workingday', 'season', 'weather']\n",
    "labeled_col = ['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[input_col]    \n",
    "y = train[labeled_col]\n",
    "X_val = test[input_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8164, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                   random_state=0)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 난수 발생 패턴 결정 0\n",
    "seed = 0\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딥러닝 구조 결정\n",
    " * 사용하는 피처(2개) - 입력층의 노드는 2개\n",
    " * 마지막 예측하는 것이 회귀 - 출력층의 노드는 1개\n",
    " * 마지막 예측하는 것이 분류(다항) - 출력층의 노드는 범주의 개수만큼 생긴다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sequential() 함수를 사용하여 한층 한층 쉽게 쌓아올릴 수 있다.\n",
    "* model.add()로 한층 또는 두층씩 추가\n",
    "* 첫 model.add() 입력층과 그 다음 출력층을 넣을 수 있다.\n",
    "* 각 은닉층이 끝나는 시점에 활성화 함수를 통해 비선형 문제를 풀 수 있게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=6, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 186\n",
      "Trainable params: 186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 배치 데이터 10개\n",
    " * (10,2) -> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평가지표\n",
    " * MSE, RMSE, RMLSE(or RMSLE), MAE\n",
    " * MSE로 평가한다면 loss='mean_squared_error'\n",
    " * optimizer-가중치를 업데이트 시켜가는데, 사용하는 알고리즘.(cs231n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 15036.1953\n",
      "Epoch 2/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 14937.3691\n",
      "Epoch 3/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 14856.6348\n",
      "Epoch 4/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 14739.6611\n",
      "Epoch 5/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 14663.1445\n",
      "Epoch 6/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 14571.4229\n",
      "Epoch 7/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 14495.7021\n",
      "Epoch 8/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 14325.9932\n",
      "Epoch 9/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 14220.7402\n",
      "Epoch 10/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 14141.6484\n",
      "Epoch 11/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 14061.8057\n",
      "Epoch 12/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 13950.8535\n",
      "Epoch 13/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 13872.2451\n",
      "Epoch 14/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 13761.4102\n",
      "Epoch 15/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 13642.7783\n",
      "Epoch 16/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 13572.9971\n",
      "Epoch 17/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 13514.4131\n",
      "Epoch 18/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 13421.7578\n",
      "Epoch 19/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 13329.2734\n",
      "Epoch 20/200\n",
      "817/817 [==============================] - 1s 2ms/step - loss: 13238.7344\n",
      "Epoch 21/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 13115.7627\n",
      "Epoch 22/200\n",
      "817/817 [==============================] - 1s 2ms/step - loss: 13053.9863\n",
      "Epoch 23/200\n",
      "817/817 [==============================] - 1s 2ms/step - loss: 12973.3730\n",
      "Epoch 24/200\n",
      "817/817 [==============================] - 1s 2ms/step - loss: 12867.5615\n",
      "Epoch 25/200\n",
      "817/817 [==============================] - 1s 2ms/step - loss: 12811.0029\n",
      "Epoch 26/200\n",
      "817/817 [==============================] - 1s 2ms/step - loss: 12697.1289\n",
      "Epoch 27/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 12645.6328\n",
      "Epoch 28/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 12546.6680\n",
      "Epoch 29/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 12462.5225\n",
      "Epoch 30/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 12410.2695\n",
      "Epoch 31/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 12323.7549\n",
      "Epoch 32/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 12221.2217\n",
      "Epoch 33/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 12185.7627\n",
      "Epoch 34/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 12104.6113\n",
      "Epoch 35/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 12028.2246\n",
      "Epoch 36/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 11904.1924\n",
      "Epoch 37/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 11913.4199\n",
      "Epoch 38/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 11775.7568\n",
      "Epoch 39/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 11730.9844\n",
      "Epoch 40/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 11640.2041\n",
      "Epoch 41/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 11574.9385\n",
      "Epoch 42/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 11504.2910\n",
      "Epoch 43/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 11446.8662\n",
      "Epoch 44/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 11346.4707\n",
      "Epoch 45/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 11347.6689\n",
      "Epoch 46/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 11249.5068\n",
      "Epoch 47/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 11054.7432\n",
      "Epoch 48/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 11041.5293\n",
      "Epoch 49/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 10960.6807\n",
      "Epoch 50/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 10875.5107\n",
      "Epoch 51/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 10748.6953\n",
      "Epoch 52/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 10634.7109\n",
      "Epoch 53/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 10651.4277\n",
      "Epoch 54/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 10574.8584\n",
      "Epoch 55/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 10481.2295\n",
      "Epoch 56/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 10453.5625\n",
      "Epoch 57/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 10331.0088\n",
      "Epoch 58/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 10403.7217\n",
      "Epoch 59/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 10224.4277\n",
      "Epoch 60/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 10219.1514\n",
      "Epoch 61/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 10168.0010\n",
      "Epoch 62/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 10188.9941\n",
      "Epoch 63/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 10079.0830\n",
      "Epoch 64/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 10005.1172\n",
      "Epoch 65/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 9914.4199\n",
      "Epoch 66/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 9918.0684\n",
      "Epoch 67/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 9837.9531\n",
      "Epoch 68/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 9823.7188\n",
      "Epoch 69/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 9740.2441\n",
      "Epoch 70/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 9778.4053\n",
      "Epoch 71/200\n",
      "817/817 [==============================] - 1s 2ms/step - loss: 9700.5586\n",
      "Epoch 72/200\n",
      "817/817 [==============================] - 1s 2ms/step - loss: 9580.3955\n",
      "Epoch 73/200\n",
      "817/817 [==============================] - 1s 2ms/step - loss: 9597.2881\n",
      "Epoch 74/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 9468.7832\n",
      "Epoch 75/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 9381.4287\n",
      "Epoch 76/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 9356.7871\n",
      "Epoch 77/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 9273.1777\n",
      "Epoch 78/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 9218.1104\n",
      "Epoch 79/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 9121.8623\n",
      "Epoch 80/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 9091.9385\n",
      "Epoch 81/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 9008.6660\n",
      "Epoch 82/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8987.0859\n",
      "Epoch 83/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8991.1592\n",
      "Epoch 84/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8953.5000\n",
      "Epoch 85/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8912.8174\n",
      "Epoch 86/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8912.2832\n",
      "Epoch 87/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8842.2285\n",
      "Epoch 88/200\n",
      "817/817 [==============================] - 1s 2ms/step - loss: 8915.5898\n",
      "Epoch 89/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8852.2402\n",
      "Epoch 90/200\n",
      "817/817 [==============================] - ETA: 0s - loss: 8818.11 - 1s 2ms/step - loss: 8820.5293\n",
      "Epoch 91/200\n",
      "817/817 [==============================] - 1s 2ms/step - loss: 8729.4512\n",
      "Epoch 92/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8719.2461\n",
      "Epoch 93/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8754.8965\n",
      "Epoch 94/200\n",
      "817/817 [==============================] - 1s 2ms/step - loss: 8733.4824\n",
      "Epoch 95/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "817/817 [==============================] - 1s 1ms/step - loss: 8674.9824\n",
      "Epoch 96/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8690.7705\n",
      "Epoch 97/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8637.1416\n",
      "Epoch 98/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8580.1816\n",
      "Epoch 99/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8625.1172\n",
      "Epoch 100/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8602.9199\n",
      "Epoch 101/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8514.3730\n",
      "Epoch 102/200\n",
      "817/817 [==============================] - 1s 2ms/step - loss: 8589.2842\n",
      "Epoch 103/200\n",
      "817/817 [==============================] - 1s 2ms/step - loss: 8533.1738\n",
      "Epoch 104/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8477.9766\n",
      "Epoch 105/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8503.5000\n",
      "Epoch 106/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8520.6787\n",
      "Epoch 107/200\n",
      "817/817 [==============================] - 1s 2ms/step - loss: 8406.0947\n",
      "Epoch 108/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8430.4570\n",
      "Epoch 109/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8429.8447\n",
      "Epoch 110/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8408.1162\n",
      "Epoch 111/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8255.1338\n",
      "Epoch 112/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8384.6094\n",
      "Epoch 113/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8308.0586\n",
      "Epoch 114/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8321.9951\n",
      "Epoch 115/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8336.5781\n",
      "Epoch 116/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8291.5830\n",
      "Epoch 117/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8246.5664\n",
      "Epoch 118/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8174.3140\n",
      "Epoch 119/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8161.8296\n",
      "Epoch 120/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8185.7393\n",
      "Epoch 121/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8203.2842\n",
      "Epoch 122/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8170.5742\n",
      "Epoch 123/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8107.2910\n",
      "Epoch 124/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8047.2954\n",
      "Epoch 125/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8127.3921\n",
      "Epoch 126/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8050.2979\n",
      "Epoch 127/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8001.5854\n",
      "Epoch 128/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8028.6724\n",
      "Epoch 129/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8031.1465\n",
      "Epoch 130/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 8021.5762\n",
      "Epoch 131/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7986.1143\n",
      "Epoch 132/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7995.2031\n",
      "Epoch 133/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7977.0718\n",
      "Epoch 134/200\n",
      "817/817 [==============================] - 1s 2ms/step - loss: 7932.5059\n",
      "Epoch 135/200\n",
      "817/817 [==============================] - 2s 2ms/step - loss: 7970.3726\n",
      "Epoch 136/200\n",
      "817/817 [==============================] - 1s 2ms/step - loss: 7882.5181\n",
      "Epoch 137/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7886.7041\n",
      "Epoch 138/200\n",
      "817/817 [==============================] - 1s 2ms/step - loss: 7879.6221\n",
      "Epoch 139/200\n",
      "817/817 [==============================] - 2s 2ms/step - loss: 7845.4438\n",
      "Epoch 140/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7890.6533\n",
      "Epoch 141/200\n",
      "817/817 [==============================] - 1s 2ms/step - loss: 7800.0986\n",
      "Epoch 142/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7838.1421\n",
      "Epoch 143/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7779.6416\n",
      "Epoch 144/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7851.9609\n",
      "Epoch 145/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7742.0679\n",
      "Epoch 146/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7749.0171\n",
      "Epoch 147/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7754.5093\n",
      "Epoch 148/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7687.7515\n",
      "Epoch 149/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7679.9131\n",
      "Epoch 150/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7704.1890\n",
      "Epoch 151/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7665.6157\n",
      "Epoch 152/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7640.0293\n",
      "Epoch 153/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7741.0068\n",
      "Epoch 154/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7680.5601\n",
      "Epoch 155/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7679.6704\n",
      "Epoch 156/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7643.4790\n",
      "Epoch 157/200\n",
      "817/817 [==============================] - 1s 2ms/step - loss: 7702.9395\n",
      "Epoch 158/200\n",
      "817/817 [==============================] - 1s 2ms/step - loss: 7597.3267\n",
      "Epoch 159/200\n",
      "817/817 [==============================] - 1s 2ms/step - loss: 7617.7598\n",
      "Epoch 160/200\n",
      "817/817 [==============================] - 1s 2ms/step - loss: 7536.6133\n",
      "Epoch 161/200\n",
      "817/817 [==============================] - 1s 2ms/step - loss: 7591.5122\n",
      "Epoch 162/200\n",
      "817/817 [==============================] - 1s 2ms/step - loss: 7488.7905\n",
      "Epoch 163/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7576.1230\n",
      "Epoch 164/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7587.9487\n",
      "Epoch 165/200\n",
      "817/817 [==============================] - 1s 2ms/step - loss: 7663.8867\n",
      "Epoch 166/200\n",
      "817/817 [==============================] - 2s 2ms/step - loss: 7578.7090\n",
      "Epoch 167/200\n",
      "817/817 [==============================] - 1s 2ms/step - loss: 7529.9253\n",
      "Epoch 168/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7526.3833\n",
      "Epoch 169/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7569.3047\n",
      "Epoch 170/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7497.2300\n",
      "Epoch 171/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7477.9243\n",
      "Epoch 172/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7477.3257\n",
      "Epoch 173/200\n",
      "817/817 [==============================] - 1s 2ms/step - loss: 7454.5342\n",
      "Epoch 174/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7500.6147\n",
      "Epoch 175/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7432.3223\n",
      "Epoch 176/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7445.6743\n",
      "Epoch 177/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7375.4097\n",
      "Epoch 178/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7377.9468\n",
      "Epoch 179/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7431.8994\n",
      "Epoch 180/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7363.5806\n",
      "Epoch 181/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7421.7788\n",
      "Epoch 182/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7507.3545\n",
      "Epoch 183/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7398.9746\n",
      "Epoch 184/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7522.2285\n",
      "Epoch 185/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7448.0146\n",
      "Epoch 186/200\n",
      "817/817 [==============================] - 1s 2ms/step - loss: 7410.4604\n",
      "Epoch 187/200\n",
      "817/817 [==============================] - 1s 2ms/step - loss: 7350.5825\n",
      "Epoch 188/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7299.6274\n",
      "Epoch 189/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "817/817 [==============================] - 1s 1ms/step - loss: 7346.8013\n",
      "Epoch 190/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7299.0562\n",
      "Epoch 191/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7377.2148\n",
      "Epoch 192/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7407.3188\n",
      "Epoch 193/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7331.2188\n",
      "Epoch 194/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7551.9858\n",
      "Epoch 195/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7312.9951\n",
      "Epoch 196/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7385.1045\n",
      "Epoch 197/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7246.3340\n",
      "Epoch 198/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7263.4116\n",
      "Epoch 199/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7345.4014\n",
      "Epoch 200/200\n",
      "817/817 [==============================] - 1s 1ms/step - loss: 7367.2930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x197a2391fa0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평가 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 0s 983us/step - loss: 7172.0405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7172.04052734375"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_val)\n",
    "sub = pd.read_csv(\"sampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['count'] = pred\n",
    "sub.loc[sub['count']<0, 'count'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"nn_sub_1109_02.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 4-1\n",
    " * 변수를 추가를 통해 성능을 향상시켜보자(5-10분)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 타이타닉 데이터 셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12) (418, 11)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"./titanic/train.csv\")\n",
    "test = pd.read_csv(\"./titanic/test.csv\")\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 피처 선택(3개) - 입력층 노드 3개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_col = ['Pclass', 'SibSp', 'Parch']\n",
    "labeled_col = ['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[ input_col ]\n",
    "y = train[ labeled_col ]\n",
    "X_val = test[ input_col ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(668, 3) (223, 3)\n",
      "\n",
      "(668, 1) (223, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print()\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(15, input_dim=3, activation='relu'))\n",
    "model.add(Dense(10, activation='relu') )\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.9197 - accuracy: 0.3862\n",
      "Epoch 2/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.7611 - accuracy: 0.3578\n",
      "Epoch 3/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.7060 - accuracy: 0.5090\n",
      "Epoch 4/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6871 - accuracy: 0.5973\n",
      "Epoch 5/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6817 - accuracy: 0.6078\n",
      "Epoch 6/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6763 - accuracy: 0.6123\n",
      "Epoch 7/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6727 - accuracy: 0.6108\n",
      "Epoch 8/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6687 - accuracy: 0.6123\n",
      "Epoch 9/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6651 - accuracy: 0.6153\n",
      "Epoch 10/100\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6623 - accuracy: 0.6123\n",
      "Epoch 11/100\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6595 - accuracy: 0.6243\n",
      "Epoch 12/100\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6573 - accuracy: 0.6287\n",
      "Epoch 13/100\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6549 - accuracy: 0.6243\n",
      "Epoch 14/100\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6515 - accuracy: 0.6257\n",
      "Epoch 15/100\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6486 - accuracy: 0.6392\n",
      "Epoch 16/100\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.6377\n",
      "Epoch 17/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6406 - accuracy: 0.6407\n",
      "Epoch 18/100\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.6557\n",
      "Epoch 19/100\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.6647\n",
      "Epoch 20/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6333 - accuracy: 0.6737\n",
      "Epoch 21/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6301 - accuracy: 0.6796\n",
      "Epoch 22/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6280 - accuracy: 0.6707\n",
      "Epoch 23/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6257 - accuracy: 0.6826\n",
      "Epoch 24/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6234 - accuracy: 0.6781\n",
      "Epoch 25/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.6841\n",
      "Epoch 26/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6204 - accuracy: 0.6781\n",
      "Epoch 27/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.6931\n",
      "Epoch 28/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6167 - accuracy: 0.6886\n",
      "Epoch 29/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6149 - accuracy: 0.6856\n",
      "Epoch 30/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.6916\n",
      "Epoch 31/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6122 - accuracy: 0.6826\n",
      "Epoch 32/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6098 - accuracy: 0.6901\n",
      "Epoch 33/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6083 - accuracy: 0.6856\n",
      "Epoch 34/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6093 - accuracy: 0.6946\n",
      "Epoch 35/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6064 - accuracy: 0.6976\n",
      "Epoch 36/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6044 - accuracy: 0.7006: 0s - loss: 0.6055 - accuracy: 0.70\n",
      "Epoch 37/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6038 - accuracy: 0.6886\n",
      "Epoch 38/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6027 - accuracy: 0.7036\n",
      "Epoch 39/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6017 - accuracy: 0.7006\n",
      "Epoch 40/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6008 - accuracy: 0.6916\n",
      "Epoch 41/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6001 - accuracy: 0.6946\n",
      "Epoch 42/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5989 - accuracy: 0.6976\n",
      "Epoch 43/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5983 - accuracy: 0.7021\n",
      "Epoch 44/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5979 - accuracy: 0.7036\n",
      "Epoch 45/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5952 - accuracy: 0.7051\n",
      "Epoch 46/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5950 - accuracy: 0.7051\n",
      "Epoch 47/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5944 - accuracy: 0.7021\n",
      "Epoch 48/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.6991\n",
      "Epoch 49/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5940 - accuracy: 0.6961\n",
      "Epoch 50/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5913 - accuracy: 0.7051\n",
      "Epoch 51/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5915 - accuracy: 0.6931\n",
      "Epoch 52/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.6976\n",
      "Epoch 53/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5903 - accuracy: 0.7036\n",
      "Epoch 54/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5906 - accuracy: 0.7051\n",
      "Epoch 55/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5892 - accuracy: 0.7006\n",
      "Epoch 56/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5880 - accuracy: 0.6976\n",
      "Epoch 57/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5886 - accuracy: 0.7036\n",
      "Epoch 58/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5875 - accuracy: 0.7036\n",
      "Epoch 59/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5875 - accuracy: 0.7036\n",
      "Epoch 60/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.7051\n",
      "Epoch 61/100\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.5869 - accuracy: 0.7006\n",
      "Epoch 62/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5882 - accuracy: 0.7021\n",
      "Epoch 63/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5862 - accuracy: 0.6961\n",
      "Epoch 64/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.6991\n",
      "Epoch 65/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5862 - accuracy: 0.7021\n",
      "Epoch 66/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5850 - accuracy: 0.7006\n",
      "Epoch 67/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5870 - accuracy: 0.7006\n",
      "Epoch 68/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.7006\n",
      "Epoch 69/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5870 - accuracy: 0.7006\n",
      "Epoch 70/100\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.7051\n",
      "Epoch 71/100\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.5849 - accuracy: 0.7006\n",
      "Epoch 72/100\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.5836 - accuracy: 0.7021: 0s - loss: 0.5959 - accuracy: \n",
      "Epoch 73/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5844 - accuracy: 0.7036: 0s - loss: 0.5745 - accuracy: 0.\n",
      "Epoch 74/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5846 - accuracy: 0.7006\n",
      "Epoch 75/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.7021\n",
      "Epoch 76/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5844 - accuracy: 0.7066\n",
      "Epoch 77/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5855 - accuracy: 0.6991\n",
      "Epoch 78/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.7096\n",
      "Epoch 79/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.7051\n",
      "Epoch 80/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5847 - accuracy: 0.6991\n",
      "Epoch 81/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5819 - accuracy: 0.7111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.7036\n",
      "Epoch 83/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5826 - accuracy: 0.6976\n",
      "Epoch 84/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.7006\n",
      "Epoch 85/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.7036\n",
      "Epoch 86/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.7051\n",
      "Epoch 87/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.7036\n",
      "Epoch 88/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.6976\n",
      "Epoch 89/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.7051\n",
      "Epoch 90/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.7096\n",
      "Epoch 91/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5820 - accuracy: 0.7021\n",
      "Epoch 92/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.7051\n",
      "Epoch 93/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5820 - accuracy: 0.7081\n",
      "Epoch 94/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5819 - accuracy: 0.7051\n",
      "Epoch 95/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.7051\n",
      "Epoch 96/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.6976\n",
      "Epoch 97/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.7021\n",
      "Epoch 98/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.7051\n",
      "Epoch 99/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.7036\n",
      "Epoch 100/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.7051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x197a281c1c0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = 'binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 997us/step - loss: 0.5759 - accuracy: 0.7309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5759212970733643, 0.7309417128562927]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived'], dtype='object')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(\"./titanic/gender_submission.csv\")\n",
    "sub.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['Survived'] = pred[:, 0] > 0.5  # True, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.loc[sub['Survived']==True, 'Survived'] = 1\n",
    "sub.loc[sub['Survived']==False, 'Survived'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"titanic_submit1109.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.69138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
